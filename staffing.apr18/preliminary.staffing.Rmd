---
title: "Staffing Analysis"
author: "Allocate Analytics"
date: "March 16, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(ggplot2)
library(sugrrants)
library(lubridate)
wd <- getwd()
setwd("C://Users/The Pritchard family/Documents/R/whaletale")
data4years <- read.csv("data/mutated.data1417.csv", stringsAsFactors = FALSE)
data4years <- filter(data4years, Register != "9")

data4years.wide <- data4years
data4years.wide$Date.Sold <- as_datetime(data4years.wide$Date.Sold)
data4years.wide$Date.Sold.Round <- floor_date(data4years.wide$Date.Sold, unit = "hour")
data4years.wide$Date.Sold <- as_date(data4years.wide$Date.Sold)

data17 <- filter(data4years.wide, Year == 2017)


data17.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Date.Sold, data17, sum)
data17.agg <- data17.agg %>%
  mutate("Hour" = as.integer(hour(Date.Sold.Round))) %>%
  frame_calendar(x = Hour, y = Total.Sales, date = Date.Sold, calendar = "monthly")
data17.plot <- data17.agg %>%
  ggplot(aes(x = .Hour, y = .Total.Sales, group = Date.Sold)) + geom_line()

```

# Hourly Sales Every Day of 2017

```{r calendar.17.plot, echo=FALSE}
#print(unique(data4years$Register))
prettify(data17.plot)
```

## Comments and Trends

1 Almost no big days until 2nd weekend of April and hen it's Fri, Sat, Sun
2 Weekdays start getting consistently big after Memorial Day
3 Weekdays slow down after Labor Day
4 October weekdays even slower than Sept.
5 Beginning around Halloween Saturday is really the main big weekend day until the week before Xmas and except for Thanksgiving weekend

\newpage

# Hourly Sales Every Day of 2016

```{r calendar.16.plot, echo=FALSE}
data16 <- filter(data4years.wide, Year == 2016)

data16.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Date.Sold, data16, sum)
data16.agg <- data16.agg %>%
  mutate("Hour" = as.integer(hour(Date.Sold.Round))) %>%
  frame_calendar(x = Hour, y = Total.Sales, date = Date.Sold, calendar = "monthly")
data16.plot <- data16.agg %>%
  ggplot(aes(x = .Hour, y = .Total.Sales, group = Date.Sold)) + geom_line()
prettify(data16.plot)

```



```{r off.peak.minimum, echo=FALSE}

data2years.wide <- filter(data4years.wide, Year %in% c(2016, 2017))

#data2years$Date.Sold <- as_date(data2years$Date.Sold)

data2years.wide <- data2years.wide %>%
  mutate("Hour" = hour(Date.Sold.Round)) %>%
  mutate("Weekday" = wday((Date.Sold.Round)))
    
# filter for off.peak.minimum ##
df1 <- data2years.wide %>%
  filter(Date.Sold >= "2016-01-01", Date.Sold <= "2016-01-31")
df2 <- data2years.wide %>%
  filter(Date.Sold >= "2016-02-01", Date.Sold <= "2016-04-07", Weekday %in% c(1, 2, 3, 4, 5, 7))

#print(head(df2))
#print(tail(df2))

df.all <- rbind(df1, df2)

# need to go back to original script and add additional start dates with defaults like 0 for min and 100000 for max
staffing.day.plot.2 <- function(df, nickname.of.time.range){
  
  library(lubridate)
  library(dplyr)
  library(ggplot2)
  
  df.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Hour + Weekday, df.all, sum)
  conf.df <- data.frame()
  
  for(i in 9:23){
    #print(i)
    i.hour.vec <- df.agg %>%
      filter(Hour == i) %>%
      select(Total.Sales)
    #i.hour.vec <- as.double(i.hour.vec)
    #print(head(i.hour.vec))
    #i.estimate.95 <- t.test(i.hour.vec, conf.level = 0.95)$estimate
    #i.conf.int.95 <- t.test(i.hour.vec, conf.level = 0.95)$conf.int
    #i.conf.int.75 <- t.test(i.hour.vec, conf.level = 0.75)$conf.int
    #i.conf.int.50 <- t.test(i.hour.vec, conf.level = 0.50)$conf.int
    #three.conf.int <- c(i, i.estimate.95, i.conf.int.95, i.conf.int.75, i.conf.int.50)
    quantiles <- quantile(as.numeric(unlist(i.hour.vec)), probs = c(.5, .025, .975, .125, .875, .25, .75))
    #print(class(quantiles))
    
    quantiles.hour <- c(i, quantiles)
    #print(class(quantiles.hour))
    conf.df <- rbind(conf.df, quantiles.hour)
    
    #i.estimate.95 <- quantie(i.hour.vec, .5)
    #i.conf.int.95.high <- 
    #quantiles.hour <- c(i, quantile(i.hour.vec, c(.5, .025, .975, .125, .875, .25, .75)))
  }
    colnames(conf.df) <- c("hour", "estimate", "low95", "high95", "low75", "high75", "low50", "high50")
    
    day.plot <- ggplot(data = conf.df, aes(x=hour)) +
      geom_ribbon(aes(ymin=low95, ymax=high95), fill="#0571b0", alpha = .75)+
      geom_ribbon(aes(ymin=low75, ymax=high75), fill="#92c5de", alpha = .75)+
      geom_ribbon(aes(ymin=low50, ymax=high50), fill="#d1e5f0", alpha = .75)+
      geom_ribbon(aes(ymin=estimate-5, ymax=estimate+5), fill="#ef8a62")
    print(day.plot)
}

#staffing.day.plot.2(df.all)


```

\newpage

### Range of Sales Per Hour for Mon-Sat July-Aug

The largest darkest blue represents the range that sales would fall 95% of the time; the medium blue is 75% of the time; the light blue is 50% of the time, and the red is exactly the middle of the range.  

If you tried to staff for the top of the light blue, you'd be able to cover the sales volume 75% of the time.

```{r peak.6.days, echo=FALSE}

# filter for off.peak.minimum ##
df1 <- data2years.wide %>%
  filter(Date.Sold >= "2016-06-25", Date.Sold <= "2016-09-03", Weekday %in% c(1, 2, 3, 4, 5, 6))
df2 <- data2years.wide %>%
  filter(Date.Sold >= "2017-06-25", Date.Sold <= "2017-09-03", Weekday %in% c(1, 2, 3, 4, 5, 6))

#print(head(df2))
#print(tail(df2))

df.all <- rbind(df1, df2)
staffing.day.plot.2(df.all)

setwd(wd)
```

